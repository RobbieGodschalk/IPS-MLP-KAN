{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "torch.manual_seed(7777)\n",
    "np.random.seed(7777)\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# print('Training will be done on the ' + 'GPU' if torch.cuda.is_available() else 'CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum, StrEnum\n",
    "\n",
    "class Scaling(Enum):\n",
    "    INDEPENDENT = 1\n",
    "    JOINT = 2\n",
    "\n",
    "class DatasetType(StrEnum):\n",
    "    TRAIN = 'trn'\n",
    "    TEST = 'tst'\n",
    "    VALIDATION = 'trn'\n",
    "\n",
    "# Global variable to enable debug mode\n",
    "DEBUG = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loading & pre-processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# *Helper function to preprocess the RSSI data\n",
    "def preprocess_rssi_data(df_rssi: pd.DataFrame, scaling_strategy: Scaling) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function preprocesses the training data by:\n",
    "    1. Replacing all 100 values with -110 (ensures continuity of data)\n",
    "    2. Separating the RSS values from the labels\n",
    "    3. Scaling the data to have zero mean and unit variance\n",
    "\n",
    "    Parameters:\n",
    "    - train: The training data to be preprocessed\n",
    "    - scaling_strategy: The scaling strategy to be used (INDEPENDENT or JOINT)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. replace all 100 values with -110 (ensures continuity of data)\n",
    "    df = df_rssi.replace(100, -110)\n",
    "    \n",
    "    # 2. Separate the RSS values from the labels\n",
    "    rssiValues = df.iloc[:, :-3]\n",
    "    labels = df.iloc[:, -3:]\n",
    "    \n",
    "    # 3. Scale the data to have zero mean and unit variance\n",
    "    # This is done either independently for each AP or jointly for all APs\n",
    "    if scaling_strategy == Scaling.INDEPENDENT:\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "\n",
    "        scaled_rss = scaler.fit_transform(rssiValues)\n",
    "        df_scaled_rss = pd.DataFrame(scaled_rss, columns=rssiValues.columns)\n",
    "        df = pd.concat([df_scaled_rss, labels], axis=1)\n",
    "    \n",
    "    elif scaling_strategy == Scaling.JOINT:\n",
    "        flattened = rssiValues.values.flatten()\n",
    "        global_mean = np.mean(flattened)\n",
    "        global_std = np.std(flattened)\n",
    "        \n",
    "        scaled_rss = (rssiValues - global_mean) / global_std\n",
    "        df = pd.concat([scaled_rss, labels], axis=1)\n",
    "        df = df.reset_index(drop=True)\n",
    "    \n",
    "    else: \n",
    "        raise NotImplementedError(\"Specified scaling strategy is not implemented, use either Scaling.INDEPENDENT or Scaling.JOINT.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# # *Load and pre-process the training data\n",
    "# def get_preprocessed_training_data(data_path: str, training_months: list[str], num_APs: int, scaling_strategy: Scaling, floor: int) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     This function loads and preprocesses the training data from the specified training months and floor.\n",
    "\n",
    "#     Parameters:\n",
    "#     - data_path: The path to the data\n",
    "#     - training_months: The list of training months to be used\n",
    "#     - num_APs: The number of access points\n",
    "#     - scaling_strategy: The scaling strategy to be used (INDEPENDENT or JOINT)\n",
    "#     - floor: The floor to be used\n",
    "#     \"\"\"\n",
    "#     # Since the csv files do not have column names, we define these first.\n",
    "#     list_of_APs = [\"AP\" + str(i) for i in range(0, num_APs)]\n",
    "\n",
    "#     # Load the training data from all specified training sets.  \n",
    "#     df_rss = pd.concat([pd.read_csv(data_path + training_set + 'trn01rss.csv', names=list_of_APs) for training_set in training_months])\n",
    "#     df_rss = df_rss.reset_index(drop=True)\n",
    "    \n",
    "#     # Get all x,y,floor labels (gotten from data_path + training_month + 'trn01crd.csv')\n",
    "#     df_labels = pd.concat([pd.read_csv(data_path + training_set + 'trn01crd.csv', names=['x', 'y', 'floor']) for training_set in training_months])\n",
    "#     df_labels = df_labels.reset_index(drop=True)\n",
    "\n",
    "#     # Add the labels to the pre-processed data\n",
    "#     df_labeled = pd.concat([df_rss, df_labels], axis=1)\n",
    "    \n",
    "#     # Filter the data to only include the specified floor\n",
    "#     df_labeled = df_labeled[df_labeled['floor'] == floor]\n",
    "\n",
    "#     # Pre-processing of the training data\n",
    "#     df_train = preprocess_rssi_data(df_labeled, scaling_strategy)\n",
    "    \n",
    "#     return df_train\n",
    "\n",
    "# *Load and pre-process the data\n",
    "def get_preprocessed_dataset(data_path: str, months: list[str], sets: list[str], type: DatasetType, num_APs: int, scaling_strategy: Scaling, floor: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function loads and preprocesses the training data from the specified training months and floor.\n",
    "\n",
    "    Parameters:\n",
    "    - data_path: The path to the data\n",
    "    - months: The list of months to be used\n",
    "    - sets: The list of set numbers to be used\n",
    "    - type: The type of dataset to be made (TRAIN, TEST or VALIDATION)\n",
    "    - num_APs: The number of access points\n",
    "    - scaling_strategy: The scaling strategy to be used (INDEPENDENT or JOINT)\n",
    "    - floor: The floor to be used\n",
    "    \"\"\"\n",
    "    # Since the csv files do not have column names, we define these first.\n",
    "    list_of_APs = [\"AP\" + str(i) for i in range(0, num_APs)]\n",
    "\n",
    "    # Load the test data from all specified test sets.  \n",
    "    df_test_rss = pd.concat([pd.read_csv(data_path + month + '/' + type + set + 'rss.csv', names=list_of_APs) for month in months for set in sets])\n",
    "    df_test_rss = df_test_rss.reset_index(drop=True)\n",
    "    \n",
    "    # Get all x,y,floor labels\n",
    "    df_test_labels = pd.concat([pd.read_csv(data_path + month + '/' + type + set + 'crd.csv', names=['x', 'y', 'floor']) for month in months for set in sets])\n",
    "    df_test_labels = df_test_labels.reset_index(drop=True)\n",
    "\n",
    "    # Add the labels to the pre-processed data\n",
    "    df_test_labeled = pd.concat([df_test_rss, df_test_labels], axis=1)\n",
    "    \n",
    "    # Filter the data to only include the specified floor\n",
    "    df_test_labeled = df_test_labeled[df_test_labeled['floor'] == floor]\n",
    "\n",
    "    # Pre-processing of the training data\n",
    "    df_test = preprocess_rssi_data(df_test_labeled, scaling_strategy)\n",
    "    \n",
    "    return df_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_full: (4320, 451)\n",
      "df_train_x: (3888, 448)\n",
      "df_train_y: (3888, 2)\n",
      "df_val_x: (432, 448)\n",
      "df_val_y: (432, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_path = './data/V1.0/'\n",
    "training_months = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15']\n",
    "sets = ['01']\n",
    "type = DatasetType.TRAIN\n",
    "num_APs = 448\n",
    "scaling_strategy = Scaling.JOINT\n",
    "floor = 3\n",
    "\n",
    "df_full = get_preprocessed_dataset(data_path, training_months, sets, type, num_APs, scaling_strategy, floor)\n",
    "\n",
    "df_x = df_full.iloc[:, :-3] # Just the RSSI values\n",
    "df_y = df_full.iloc[:, -3:-1] # Just the x and y coordinates (no floor)\n",
    "\n",
    "df_train_x, df_val_x, df_train_y, df_val_y = train_test_split(df_x, df_y, test_size=0.1, random_state=7777)\n",
    "\n",
    "if DEBUG: print('df_full:', df_full.shape)\n",
    "if DEBUG: print('df_train_x:', df_train_x.shape)\n",
    "if DEBUG: print('df_train_y:', df_train_y.shape)\n",
    "if DEBUG: print('df_val_x:', df_val_x.shape)\n",
    "if DEBUG: print('df_val_y:', df_val_y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_test01-02-03_full: (12960, 451)\n"
     ]
    }
   ],
   "source": [
    "months = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15']\n",
    "sets = ['01', '02', '03'] # 01 Corresponds to the same locations as the training set - All with same direction\n",
    "type = DatasetType.TEST\n",
    "\n",
    "df_test_full = get_preprocessed_dataset(data_path, months, sets, type, num_APs, scaling_strategy, floor)\n",
    "df_test_x = df_test_full.iloc[:, :-3] # Just the RSSI values\n",
    "df_test_y = df_test_full.iloc[:, -3:-1] # Just the x and y coordinates (no floor)\n",
    "\n",
    "if DEBUG: print('df_test01-02-03_full:', df_test_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# months = ['01']\n",
    "# sets = ['02', '03', '04']\n",
    "# type = DatasetType.VALIDATION\n",
    "\n",
    "# df_val_full = get_preprocessed_dataset(data_path, months, sets, type, num_APs, scaling_strategy, floor)\n",
    "# df_val_x = df_val_full.iloc[:, :-3] # Just the RSSI values\n",
    "# df_val_y = df_val_full.iloc[:, -3:-1] # Just the x and y coordinates (no floor)\n",
    "\n",
    "# if DEBUG: print('df_val_full:', df_val_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Since the implementations will be made in PyTorch, we convert the data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(df_train_x.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(df_train_y.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(df_test_x.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(df_test_y.values, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(df_val_x.values, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(df_val_y.values, dtype=torch.float32)\n",
    "\n",
    "# Get the data via DataLoaders\n",
    "t_training = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "t_test = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "t_val = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "# train_loader = DataLoader(t_training, batch_size=16, shuffle=True)\n",
    "# test_loader = DataLoader(t_test, batch_size=16, shuffle=True)\n",
    "# val_loader = DataLoader(t_val, batch_size=16, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiLayer Perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full-Input MLP\n",
    "This network takes the full input of 448 features to perform x,y predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import copy\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, hidden_layer_sizes, dropout_rate, input_dim=448):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        \n",
    "        # Make it easier to grid-search different sizes of hidden layers\n",
    "        for hidden_dim in hidden_layer_sizes:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            input_dim = hidden_dim # Update input_dim for next layer\n",
    "        \n",
    "        # At this point we know input_dim equals the output size of the last hidden layer, so we can re-use it here.\n",
    "        layers.append(nn.Linear(input_dim, 2)) # x,y output\n",
    "        \n",
    "        # Construct the actual model based on the layers defined above.\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "\n",
    "def train_MLP(model, train_loader, val_loader, criterion, optimizer, epochs):\n",
    "    \n",
    "    # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    # Early stopping variables\n",
    "    best_model_wts = None\n",
    "    best_val_loss = np.inf\n",
    "    epochs_without_improvement = 0\n",
    "    epochs_to_use = 0\n",
    "    patience = 10\n",
    "    \n",
    "    # Training/Validation loops\n",
    "    for epoch in range(epochs):\n",
    "        model.train() # Sets the model to training mode\n",
    "        running_loss = 0.0 # Keep track of the (MSE) loss\n",
    "        \n",
    "        # Actual training loop\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device) \n",
    "            \n",
    "            # Extra case for LGFBS\n",
    "            def closure():\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    return loss\n",
    "            \n",
    "            if isinstance(optimizer, torch.optim.LBFGS):\n",
    "                optimizer.step(closure)\n",
    "                loss = closure()\n",
    "            \n",
    "            else:\n",
    "                optimizer.zero_grad() # Reset gradients from last iteration\n",
    "                outputs = model(inputs) # Forward pass\n",
    "                loss = criterion(outputs, labels) # Compute the loss (MSE) between the predictions and the ground-truth labels\n",
    "                loss.backward() # Perform backpropagation\n",
    "                optimizer.step() # Update model parameters (weights) based on the gradients computed during backpropagation\n",
    "            \n",
    "            running_loss += loss.item() # Running loss is the sum of the losses for all batches FOR THE CURRENT EPOCH \n",
    "        \n",
    "        # Validation time\n",
    "        model.eval()\n",
    "        val_loss = 0.0 # Accumulated validation loss\n",
    "        \n",
    "        # Validation loop\n",
    "        with torch.no_grad(): # No need to compute gradients during validation\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device) # Move data to GPU if available\n",
    "                \n",
    "                outputs = model(inputs) # Forward pass to get predictions\n",
    "                loss = criterion(outputs, labels) # Compute the loss (MSE) between the predictions and the ground-truth labels\n",
    "                val_loss += loss.item() # Accumulate the validation loss for this epoch <-- TODO: (Make list for final model to plot)\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        # Print the loss for this epoch\n",
    "        print(f'Epoch {epoch+1}/{epochs} - Avg Training Loss: {running_loss/len(train_loader)} - Avg Validation Loss: {val_loss/len(val_loader)}')\n",
    "    \n",
    "        # Early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            epochs_to_use = epoch+1\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "        \n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f'Early stopping after {epoch+1} epochs without improvement. Use model from epoch {epochs_to_use}')\n",
    "            break\n",
    "    \n",
    "    if best_model_wts is not None:\n",
    "        model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    print('Finished Training')\n",
    "    return best_val_loss, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduced-Input MLP\n",
    "Use either stacked or deep autoencoder to reduce the input space before training a MLP network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Simple auto-encoder class with a single hidden layer\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder - Compress input data\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Decoder - Reconstruct input data\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "\n",
    "\n",
    "\n",
    "# Function to train a *single* autoencoder\n",
    "def train_autoencoder(autoencoder, data_loader, criterion, optimizer, epochs):\n",
    "    autoencoder.to(device) # Move model to GPU if available\n",
    "    \n",
    "    # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        autoencoder.train() # Enable training mode\n",
    "        running_loss = 0.0 # Running loss for this epoch\n",
    "        \n",
    "        for inputs, _ in data_loader: # Unsupervised learning, so we don't need the labels\n",
    "            inputs = inputs.to(device) # Move data to GPU if available\n",
    "            \n",
    "            optimizer.zero_grad() # Reset gradients from last iteration\n",
    "            \n",
    "            _, outputs = autoencoder(inputs) # Forward pass - only care about the reconstructed data to compute the loss with.\n",
    "            loss = criterion(outputs, inputs) # Compute the loss between the reconstructed data and the original input\n",
    "            \n",
    "            loss.backward() # Compute gradients\n",
    "            optimizer.step() # Update model params based on gradients\n",
    "            \n",
    "            running_loss += loss.item() # Accumulate loss, item() is used to extract the actual loss value from the tensor\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs} - Avg Training Loss: {running_loss/len(data_loader)}')\n",
    "\n",
    "# Function to, sequentially, train a stack of autoencoders\n",
    "def train_stacked_autoencoders(train_data, input_dim, num_encoders, epochs=20):\n",
    "    train_dataset = TensorDataset(train_data, train_data) # Autoencoders are unsupervised, so the input data is also the target data\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    \n",
    "    encoders = [] # List to store the trained autoencoders\n",
    "    current_dim = input_dim # The current input dimension\n",
    "    # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    for enc_out in num_encoders:\n",
    "        autoencoder = Autoencoder(current_dim, enc_out).to(device) # Create a new autoencoder\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.001)\n",
    "        \n",
    "        # Train the autoencoder\n",
    "        train_autoencoder(autoencoder, train_loader, criterion, optimizer, epochs)\n",
    "        \n",
    "        encoders.append(autoencoder) # Add the trained autoencoder to the list\n",
    "        \n",
    "        # Update input data to the encoded data from the current autoencoder\n",
    "        train_data = get_encoded_data(autoencoder, train_loader)\n",
    "        train_dataset = TensorDataset(train_data, train_data)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "        \n",
    "        current_dim = enc_out # Update the current input dimension\n",
    "    \n",
    "    return encoders\n",
    "\n",
    "# Utility function to get the encoded data from the autoencoder\n",
    "def get_encoded_data(autoencoder, data_loader):\n",
    "    encoded_data = []\n",
    "\n",
    "    autoencoder.eval() # Set model to evaluation mode\n",
    "    \n",
    "    with torch.no_grad(): # No need to compute gradients during inference\n",
    "        for inputs, _ in data_loader: # Unsupervised learning, so we don't need the labels\n",
    "            inputs = inputs.to(device) # Move data to GPU if available\n",
    "            \n",
    "            encoded, _ = autoencoder(inputs) # Forward pass - only care about the encoded data\n",
    "            encoded_data.append(encoded)\n",
    "    \n",
    "    return torch.cat(encoded_data, dim=0) # Concatenate all encoded data into a single tensor\n",
    "\n",
    "def stacked_encode_data(data, encoders):\n",
    "    \"\"\"\n",
    "    Function to encode data using a stack of autoencoders.\n",
    "    Assumes that the autoencoders have already been trained.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: The data to be encoded\n",
    "    - encoders: The stack of trained autoencoders to be used (provided as ordered list)\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        for encoder in encoders:\n",
    "            data = data.to(device)\n",
    "            data, _ = encoder(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def MLP_full_optimize(trial, optim : str = 'Adam') -> float:\n",
    "    # Hyper-parameters to be optimized\n",
    "    # hidden_layer_size = trial.suggest_categorical('hidden_layer_size', [700, 512, 256, 128])\n",
    "    hidden_layer_count = trial.suggest_int('hidden_layer_count', 2, 4) # inclusive\n",
    "    hidden_layer_sizes = [trial.suggest_categorical(f'hidden_layer_size_{i}', [640, 576, 512, 448, 256, 128, 64, 32, 16]) for i in range(hidden_layer_count)]\n",
    "    # hidden_layer_sizes = (hidden_layer_size,) * hidden_layer_count\n",
    "    \n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.6)\n",
    "    lr = trial.suggest_float('lr', 0.001, 0.01)\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 512, step=16)\n",
    "    epochs = trial.suggest_int('epochs', 50, 150)\n",
    "    \n",
    "    # Initialize the model\n",
    "    model = MLP(hidden_layer_sizes, dropout_rate)\n",
    "    \n",
    "    if optim.lower() == 'adam': optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    elif optim.lower() == 'lbfgs': optimizer = torch.optim.LBFGS(model.parameters(), lr=lr)\n",
    "    else : raise ValueError('Unknown optimizer')\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Use chosen batch size instead of pre-defined one\n",
    "    train_loader = DataLoader(t_training, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(t_val, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Train the model, return validation loss\n",
    "    val_loss, trained_model = train_MLP(model, train_loader, val_loader, criterion, optimizer, epochs)\n",
    "    \n",
    "    return val_loss, trained_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def MLP_SAE_optimize(trial, SAE, input_size, optim : str = 'Adam') -> float:\n",
    "    # Hyper-parameters to be optimized\n",
    "    \n",
    "    # hidden_layer_size = trial.suggest_categorical('hidden_layer_size', [256, 128, 64, 32, 16])\n",
    "    hidden_layer_count = trial.suggest_int('hidden_layer_count', 2, 4) # inclusive\n",
    "    hidden_layer_sizes = [trial.suggest_categorical(f'hidden_layer_size_{i}', [640, 576, 512, 448, 256, 128, 64, 32, 16]) for i in range(hidden_layer_count)]\n",
    "    \n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.6)\n",
    "    lr = trial.suggest_float('lr', 0.001, 0.01)\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 512, step=16)\n",
    "    epochs = trial.suggest_int('epochs', 50, 150)\n",
    "    \n",
    "    # Initialize the model\n",
    "    model = MLP(hidden_layer_sizes, dropout_rate, input_size)\n",
    "    \n",
    "    \n",
    "    if optim.lower() == 'adam': optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    elif optim.lower() == 'lbfgs': optimizer = torch.optim.LBFGS(model.parameters(), lr=lr)\n",
    "    else : raise ValueError('Unknown optimizer')\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Use chosen batch size instead of pre-defined one\n",
    "    \n",
    "    # Encode training and validation data using the stacked autoencoders in SAE\n",
    "    train_data_encoded = stacked_encode_data(X_train_tensor, SAE)\n",
    "    val_data_encoded = stacked_encode_data(X_val_tensor, SAE)\n",
    "    \n",
    "    train_loader = DataLoader(TensorDataset(train_data_encoded, y_train_tensor), batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(val_data_encoded, y_val_tensor), batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    \n",
    "    # Train the model, return validation loss\n",
    "    val_loss, trained_model = train_MLP(model, train_loader, val_loader, criterion, optimizer, epochs)\n",
    "    \n",
    "    return val_loss, trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use the following booleans to enable or disable the grid-search for the different models.\n",
    "# After running the grid-search, train the final models with the best hyperparameters.\n",
    "\n",
    "SEARCH_MLP_FULL = True\n",
    "SEARCH_MLP_REDUCED_128 = True\n",
    "SEARCH_MLP_REDUCED_64 = True\n",
    "\n",
    "TRIALS_MLP = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-14 22:04:09,404] A new study created in memory with name: no-name-f2c560d3-27b6-484b-a7f9-074858258b2c\n",
      "[I 2024-06-14 22:04:12,196] Trial 0 finished with value: 7.809223175048828 and parameters: {'hidden_layer_count': 4, 'hidden_layer_size_0': 16, 'hidden_layer_size_1': 32, 'hidden_layer_size_2': 128, 'hidden_layer_size_3': 576, 'dropout_rate': 0.5790012622706464, 'lr': 0.006440435951623098, 'batch_size': 512, 'epochs': 61}. Best is trial 0 with value: 7.809223175048828.\n",
      "[I 2024-06-14 22:04:13,483] Trial 1 finished with value: 13.039700984954834 and parameters: {'hidden_layer_count': 4, 'hidden_layer_size_0': 64, 'hidden_layer_size_1': 576, 'hidden_layer_size_2': 576, 'hidden_layer_size_3': 32, 'dropout_rate': 0.34020304112984767, 'lr': 0.002936307300227641, 'batch_size': 256, 'epochs': 96}. Best is trial 0 with value: 7.809223175048828.\n",
      "[I 2024-06-14 22:04:15,578] Trial 2 finished with value: 4.641848564147949 and parameters: {'hidden_layer_count': 2, 'hidden_layer_size_0': 448, 'hidden_layer_size_1': 16, 'dropout_rate': 0.27882562028163516, 'lr': 0.0018549856654114457, 'batch_size': 512, 'epochs': 88}. Best is trial 2 with value: 4.641848564147949.\n",
      "[I 2024-06-14 22:04:22,658] Trial 3 finished with value: 14.783485412597656 and parameters: {'hidden_layer_count': 3, 'hidden_layer_size_0': 256, 'hidden_layer_size_1': 512, 'hidden_layer_size_2': 640, 'dropout_rate': 0.4488781954798339, 'lr': 0.0069918970631966644, 'batch_size': 384, 'epochs': 102}. Best is trial 2 with value: 4.641848564147949.\n",
      "[I 2024-06-14 22:04:23,289] Trial 4 finished with value: 13.65196418762207 and parameters: {'hidden_layer_count': 3, 'hidden_layer_size_0': 32, 'hidden_layer_size_1': 64, 'hidden_layer_size_2': 256, 'dropout_rate': 0.3280261831179051, 'lr': 0.003958533874173424, 'batch_size': 224, 'epochs': 84}. Best is trial 2 with value: 4.641848564147949.\n",
      "[I 2024-06-14 22:04:24,331] Trial 5 finished with value: 11.763211250305176 and parameters: {'hidden_layer_count': 4, 'hidden_layer_size_0': 128, 'hidden_layer_size_1': 128, 'hidden_layer_size_2': 576, 'hidden_layer_size_3': 32, 'dropout_rate': 0.4996758791812306, 'lr': 0.0012977054981843387, 'batch_size': 144, 'epochs': 105}. Best is trial 2 with value: 4.641848564147949.\n",
      "[I 2024-06-14 22:04:28,293] Trial 6 finished with value: 1.8383073806762695 and parameters: {'hidden_layer_count': 3, 'hidden_layer_size_0': 256, 'hidden_layer_size_1': 512, 'hidden_layer_size_2': 64, 'dropout_rate': 0.2648392517340046, 'lr': 0.002093597198598859, 'batch_size': 432, 'epochs': 146}. Best is trial 6 with value: 1.8383073806762695.\n",
      "[I 2024-06-14 22:04:29,681] Trial 7 finished with value: 14.366448720296225 and parameters: {'hidden_layer_count': 2, 'hidden_layer_size_0': 512, 'hidden_layer_size_1': 448, 'dropout_rate': 0.4537946298806777, 'lr': 0.007942917060109446, 'batch_size': 192, 'epochs': 62}. Best is trial 6 with value: 1.8383073806762695.\n",
      "[I 2024-06-14 22:04:31,746] Trial 8 finished with value: 6.57850980758667 and parameters: {'hidden_layer_count': 4, 'hidden_layer_size_0': 448, 'hidden_layer_size_1': 128, 'hidden_layer_size_2': 448, 'hidden_layer_size_3': 448, 'dropout_rate': 0.26634477008281604, 'lr': 0.0028489967131579146, 'batch_size': 320, 'epochs': 137}. Best is trial 6 with value: 1.8383073806762695.\n",
      "[I 2024-06-14 22:04:32,326] Trial 9 finished with value: 38.97440147399902 and parameters: {'hidden_layer_count': 4, 'hidden_layer_size_0': 32, 'hidden_layer_size_1': 256, 'hidden_layer_size_2': 64, 'hidden_layer_size_3': 64, 'dropout_rate': 0.5030179566730169, 'lr': 0.0025727120705175983, 'batch_size': 272, 'epochs': 119}. Best is trial 6 with value: 1.8383073806762695.\n",
      "[I 2024-06-14 22:04:37,969] Trial 10 finished with value: 3.6049510070255826 and parameters: {'hidden_layer_count': 3, 'hidden_layer_size_0': 640, 'hidden_layer_size_1': 512, 'hidden_layer_size_2': 16, 'dropout_rate': 0.22999720443778882, 'lr': 0.009786637853048032, 'batch_size': 64, 'epochs': 147}. Best is trial 6 with value: 1.8383073806762695.\n",
      "[I 2024-06-14 22:04:42,069] Trial 11 finished with value: 5.68411217795478 and parameters: {'hidden_layer_count': 3, 'hidden_layer_size_0': 640, 'hidden_layer_size_1': 512, 'hidden_layer_size_2': 16, 'dropout_rate': 0.20239731575522202, 'lr': 0.009212427425026794, 'batch_size': 48, 'epochs': 144}. Best is trial 6 with value: 1.8383073806762695.\n",
      "[I 2024-06-14 22:04:59,120] Trial 12 finished with value: 2.040573561633075 and parameters: {'hidden_layer_count': 3, 'hidden_layer_size_0': 256, 'hidden_layer_size_1': 512, 'hidden_layer_size_2': 64, 'dropout_rate': 0.20248458121998927, 'lr': 0.004905974518458003, 'batch_size': 16, 'epochs': 127}. Best is trial 6 with value: 1.8383073806762695.\n",
      "[I 2024-06-14 22:05:01,488] Trial 13 finished with value: 1.8680309653282166 and parameters: {'hidden_layer_count': 2, 'hidden_layer_size_0': 256, 'hidden_layer_size_1': 512, 'dropout_rate': 0.3558041543140859, 'lr': 0.00471910816227665, 'batch_size': 384, 'epochs': 126}. Best is trial 6 with value: 1.8383073806762695.\n",
      "[I 2024-06-14 22:05:03,810] Trial 14 finished with value: 1.861421287059784 and parameters: {'hidden_layer_count': 2, 'hidden_layer_size_0': 256, 'hidden_layer_size_1': 640, 'dropout_rate': 0.36169826090889634, 'lr': 0.004657184202009896, 'batch_size': 416, 'epochs': 124}. Best is trial 6 with value: 1.8383073806762695.\n",
      "[I 2024-06-14 22:05:07,640] Trial 15 finished with value: 1.430294156074524 and parameters: {'hidden_layer_count': 2, 'hidden_layer_size_0': 576, 'hidden_layer_size_1': 640, 'dropout_rate': 0.39077224906489694, 'lr': 0.003874548023393121, 'batch_size': 416, 'epochs': 115}. Best is trial 15 with value: 1.430294156074524.\n",
      "[I 2024-06-14 22:05:15,000] Trial 16 finished with value: 1.536278247833252 and parameters: {'hidden_layer_count': 2, 'hidden_layer_size_0': 576, 'hidden_layer_size_1': 640, 'dropout_rate': 0.4081260153920167, 'lr': 0.0033397170871511178, 'batch_size': 464, 'epochs': 115}. Best is trial 15 with value: 1.430294156074524.\n",
      "[I 2024-06-14 22:05:23,644] Trial 17 finished with value: 1.5708669424057007 and parameters: {'hidden_layer_count': 2, 'hidden_layer_size_0': 576, 'hidden_layer_size_1': 640, 'dropout_rate': 0.4171884661182079, 'lr': 0.0037021503882449514, 'batch_size': 464, 'epochs': 111}. Best is trial 15 with value: 1.430294156074524.\n",
      "[I 2024-06-14 22:05:31,431] Trial 18 finished with value: 1.8109964728355408 and parameters: {'hidden_layer_count': 2, 'hidden_layer_size_0': 576, 'hidden_layer_size_1': 640, 'dropout_rate': 0.3987402070534148, 'lr': 0.006206816890493465, 'batch_size': 320, 'epochs': 82}. Best is trial 15 with value: 1.430294156074524.\n",
      "[I 2024-06-14 22:05:35,391] Trial 19 finished with value: 2.439878463745117 and parameters: {'hidden_layer_count': 2, 'hidden_layer_size_0': 576, 'hidden_layer_size_1': 640, 'dropout_rate': 0.5940113455204719, 'lr': 0.0037469476819072915, 'batch_size': 352, 'epochs': 114}. Best is trial 15 with value: 1.430294156074524.\n",
      "[I 2024-06-14 22:05:44,565] A new study created in memory with name: no-name-a0ae6925-7b20-4538-901f-08a5ebc7219e\n",
      "[W 2024-06-14 22:05:44,620] Trial 0 failed with parameters: {'hidden_layer_count': 2, 'hidden_layer_size_0': 64, 'hidden_layer_size_1': 64, 'dropout_rate': 0.20401035700018166, 'lr': 0.008336419073895929, 'batch_size': 176, 'epochs': 62} because of the following error: RuntimeError('mat1 and mat2 shapes cannot be multiplied (176x256 and 128x64)').\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Repositories\\IPS-MLP-KAN\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Robbie\\AppData\\Local\\Temp\\ipykernel_3196\\546210455.py\", line 68, in <lambda>\n",
      "    study.optimize(lambda trial: MLP_SAE_optimize(trial, encoders, 128, 'Adam')[0], n_trials=TRIALS_MLP)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Robbie\\AppData\\Local\\Temp\\ipykernel_3196\\1920162158.py\", line 69, in MLP_SAE_optimize\n",
      "    val_loss, trained_model = train_MLP(model, train_loader, val_loader, criterion, optimizer, epochs)\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Robbie\\AppData\\Local\\Temp\\ipykernel_3196\\4264815361.py\", line 62, in train_MLP\n",
      "    outputs = model(inputs) # Forward pass\n",
      "              ^^^^^^^^^^^^^\n",
      "  File \"d:\\Repositories\\IPS-MLP-KAN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repositories\\IPS-MLP-KAN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Robbie\\AppData\\Local\\Temp\\ipykernel_3196\\4264815361.py\", line 24, in forward\n",
      "    return self.model(x)\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"d:\\Repositories\\IPS-MLP-KAN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repositories\\IPS-MLP-KAN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repositories\\IPS-MLP-KAN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"d:\\Repositories\\IPS-MLP-KAN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repositories\\IPS-MLP-KAN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Repositories\\IPS-MLP-KAN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 116, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (176x256 and 128x64)\n",
      "[W 2024-06-14 22:05:44,647] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (176x256 and 128x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 68\u001b[0m\n\u001b[0;32m     65\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(enc\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./models/MLP/128_encoder_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m256\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mi)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     67\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 68\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mMLP_SAE_optimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAdam\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTRIALS_MLP\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m pretty_print_study(study)\n\u001b[0;32m     71\u001b[0m save_best_MLP(study, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./models/MLP/256_MLP.pth\u001b[39m\u001b[38;5;124m'\u001b[39m, encoders, \u001b[38;5;241m128\u001b[39m)\n",
      "File \u001b[1;32md:\\Repositories\\IPS-MLP-KAN\\.venv\\Lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Repositories\\IPS-MLP-KAN\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32md:\\Repositories\\IPS-MLP-KAN\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32md:\\Repositories\\IPS-MLP-KAN\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    246\u001b[0m ):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32md:\\Repositories\\IPS-MLP-KAN\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[35], line 68\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     65\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(enc\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./models/MLP/128_encoder_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m256\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mi)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     67\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 68\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43mMLP_SAE_optimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAdam\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m], n_trials\u001b[38;5;241m=\u001b[39mTRIALS_MLP)\n\u001b[0;32m     70\u001b[0m pretty_print_study(study)\n\u001b[0;32m     71\u001b[0m save_best_MLP(study, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./models/MLP/256_MLP.pth\u001b[39m\u001b[38;5;124m'\u001b[39m, encoders, \u001b[38;5;241m128\u001b[39m)\n",
      "Cell \u001b[1;32mIn[33], line 69\u001b[0m, in \u001b[0;36mMLP_SAE_optimize\u001b[1;34m(trial, SAE, input_size, optim)\u001b[0m\n\u001b[0;32m     65\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(TensorDataset(val_data_encoded, y_val_tensor), batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Train the model, return validation loss\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m val_loss, trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_MLP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m val_loss, trained_model\n",
      "Cell \u001b[1;32mIn[31], line 62\u001b[0m, in \u001b[0;36mtrain_MLP\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, epochs)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad() \u001b[38;5;66;03m# Reset gradients from last iteration\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels) \u001b[38;5;66;03m# Compute the loss (MSE) between the predictions and the ground-truth labels\u001b[39;00m\n\u001b[0;32m     64\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward() \u001b[38;5;66;03m# Perform backpropagation\u001b[39;00m\n",
      "File \u001b[1;32md:\\Repositories\\IPS-MLP-KAN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Repositories\\IPS-MLP-KAN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[31], line 24\u001b[0m, in \u001b[0;36mMLP.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Repositories\\IPS-MLP-KAN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Repositories\\IPS-MLP-KAN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Repositories\\IPS-MLP-KAN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32md:\\Repositories\\IPS-MLP-KAN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Repositories\\IPS-MLP-KAN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Repositories\\IPS-MLP-KAN\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (176x256 and 128x64)"
     ]
    }
   ],
   "source": [
    "%%capture MLP_opt_out\n",
    "\n",
    "import optuna\n",
    "\n",
    "def pretty_print_study(study):\n",
    "    print('====================================')\n",
    "    print('Number of finished trials:', len(study.trials))\n",
    "    print('Best trial:')\n",
    "    trial = study.best_trial\n",
    "    print('     Trial Number: ', trial.number)\n",
    "    print('     Duration: ', trial.duration.total_seconds())\n",
    "    print('     Value: ', trial.value)\n",
    "    print('     Params: ')\n",
    "    for key, value in trial.params.items():\n",
    "        print(f'         {key}: {value}')\n",
    "\n",
    "def save_best_MLP(study, path, SAE=None, input_size=448):\n",
    "    best_trial = study.best_trial\n",
    "    \n",
    "    hidden_layer_sizes = [best_trial.params[f'hidden_layer_size_{i}'] for i in range(best_trial.params['hidden_layer_count'])]\n",
    "    model = MLP(hidden_layer_sizes, best_trial.params['dropout_rate'], input_size)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=best_trial.params['lr'])\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    if SAE is not None: # Encode training and validation data using the stacked autoencoders in SAE\n",
    "        train_data_encoded = stacked_encode_data(X_train_tensor, SAE)\n",
    "        val_data_encoded = stacked_encode_data(X_val_tensor, SAE)\n",
    "        \n",
    "        train_loader = DataLoader(TensorDataset(train_data_encoded, y_train_tensor), batch_size=best_trial.params['batch_size'], shuffle=True)\n",
    "        val_loader = DataLoader(TensorDataset(val_data_encoded, y_val_tensor), batch_size=best_trial.params['batch_size'], shuffle=True)\n",
    "    else :\n",
    "        train_loader = DataLoader(t_training, batch_size=best_trial.params['batch_size'], shuffle=True)\n",
    "        val_loader = DataLoader(t_val, batch_size=best_trial.params['batch_size'], shuffle=True)\n",
    "    \n",
    "    val_loss, trained_model = train_MLP(model, train_loader, val_loader, criterion, optimizer, best_trial.params['epochs'])\n",
    "    \n",
    "    torch.save(trained_model.state_dict(), path)\n",
    "\n",
    "if SEARCH_MLP_FULL:\n",
    "    print('Starting MLP full grid search')\n",
    "\n",
    "    # Optuna study object and direction (minimize validation loss)\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    # study.optimize(MLP_full_gridsearch, n_trials=2)\n",
    "    study.optimize(lambda trial: MLP_full_optimize(trial, 'Adam')[0], n_trials=TRIALS_MLP)\n",
    "\n",
    "    pretty_print_study(study)\n",
    "\n",
    "    # Save trained model from best trial\n",
    "    best_trial = study.best_trial\n",
    "    save_best_MLP(study, f'./models/MLP/full_MLP.pth')\n",
    "    \n",
    "else: print('Skipping SEARCH_MLP_FULL')\n",
    "\n",
    "print('\\n====================================')\n",
    "print('V results for SEARCH_MLP_REDUCED_128 V')\n",
    "print('====================================\\n')\n",
    "\n",
    "\n",
    "if SEARCH_MLP_REDUCED_128:\n",
    "    print('Starting MLP reduced grid search for 256-128 SAE')\n",
    "\n",
    "    encoders = train_stacked_autoencoders(X_train_tensor, 448, [256, 128], 20)\n",
    "    \n",
    "    # Save the encoders for later use\n",
    "    for i, enc in enumerate(encoders):\n",
    "        torch.save(enc.state_dict(), f'./models/MLP/128_encoder_{int(256 * 0.5**i)}.pth')\n",
    "    \n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(lambda trial: MLP_SAE_optimize(trial, encoders, 128, 'Adam')[0], n_trials=TRIALS_MLP)\n",
    "    \n",
    "    pretty_print_study(study)\n",
    "    save_best_MLP(study, f'./models/MLP/128_MLP.pth', encoders, 128)\n",
    "    \n",
    "\n",
    "else: print('Skipping SEARCH_MLP_REDUCED_128') \n",
    "\n",
    "print('\\n====================================')\n",
    "print('V results for SEARCH_MLP_REDUCED_64 V')\n",
    "print('====================================\\n')\n",
    "\n",
    "if SEARCH_MLP_REDUCED_64:\n",
    "    print('Starting MLP reduced grid search for 256-128-64 SAE')\n",
    "\n",
    "    encoders = train_stacked_autoencoders(X_train_tensor, 448, [256, 128, 64], 20)\n",
    "    \n",
    "    # Save the encoders for later use\n",
    "    for i, enc in enumerate(encoders):\n",
    "        torch.save(enc.state_dict(), f'./models/MLP/64_encoder_{int(256 * 0.5**i)}.pth')\n",
    "    \n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(lambda trial: MLP_SAE_optimize(trial, encoders, 64, 'Adam')[0], n_trials=TRIALS_MLP)\n",
    "    \n",
    "    pretty_print_study(study)\n",
    "    save_best_MLP(study, f'./models/MLP/64_MLP.pth', encoders, 64)\n",
    "\n",
    "else: print('Skipping SEARCH_MLP_REDUCED_64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "filename = now.strftime(\"./optimization/MLP/MLP optimization 448AP - \"\"%Y-%m-%d-%H-%M-%S\") + '.txt'\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "    f.write(MLP_opt_out.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kolmogorov Arnold Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full-Input KAN\n",
    "This network takes the full input of 448 features to perform x,y predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def train_KAN(kan_model, train_loader, val_loader, criterion, optimizer, epochs):\n",
    "    # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    kan_model.to(device) # Move model to GPU if available\n",
    "    \n",
    "    # Early stopping variables\n",
    "    best_model_wts = None\n",
    "    best_val_loss = np.inf\n",
    "    epochs_without_improvement = 0\n",
    "    epochs_to_use = 0\n",
    "    patience = 10\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        kan_model.train() # Sets the model to training mode\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device) # Move data to GPU if available\n",
    "            \n",
    "            def closure():\n",
    "                optimizer.zero_grad()\n",
    "                outputs = kan_model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                return loss\n",
    "                \n",
    "            if isinstance(optimizer, torch.optim.LBFGS):\n",
    "                optimizer.step(closure)\n",
    "                loss = closure()\n",
    "            else:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = kan_model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() # Accumulate the loss for this epoch\n",
    "        \n",
    "        kan_model.eval()\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        # Validation loop\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                outputs = kan_model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        # Print the loss for this epoch\n",
    "        print(f'Epoch {epoch+1}/{epochs} - Avg Training Loss: {running_loss/len(train_loader)} - Avg Validation Loss: {val_loss/len(val_loader)}')\n",
    "    \n",
    "        # Early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_wts = copy.deepcopy(kan_model.state_dict())\n",
    "            epochs_to_use = epoch+1\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "        \n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f'Early stopping after {epoch+1} epochs without improvement. Use model from epoch {epochs_to_use}')\n",
    "            break\n",
    "        \n",
    "    if best_model_wts is not None:\n",
    "        kan_model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    print('Finished Training')\n",
    "    return best_val_loss, kan_model # Return the besaverage validation loss for final epoch (taking early stopping into account) AND the model itself (for evaluation use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastkan import FastKAN as KAN\n",
    "import optuna\n",
    "\n",
    "def KAN_full_optimize(trial, optim : str = 'Adam') -> float:\n",
    "    # Hyper-parameters to be optimized\n",
    "    \n",
    "    hidden_layer_count = trial.suggest_int('hidden_layer_count', 2, 4) # inclusive\n",
    "    hidden_layer_sizes = [trial.suggest_categorical(f'hidden_layer_size_{i}', [640, 576, 512, 448, 256, 128, 64, 32, 16]) for i in range(hidden_layer_count)]\n",
    "    kan_layers = [448] + hidden_layer_sizes + [2] # Ensure correct input/output size\n",
    "\n",
    "    print(kan_layers)\n",
    "    \n",
    "    learning_rate = trial.suggest_float('lr', 0.001, 0.01)\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 512, step=16)\n",
    "    epochs = trial.suggest_int('epochs', 50, 150)\n",
    "    \n",
    "    # Initialize the model\n",
    "    model = KAN(kan_layers) # We use the FastKAN implementation.\n",
    "    \n",
    "    if optim.lower() == 'adam': optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    elif optim.lower() == 'lbfgs': optimizer = torch.optim.LBFGS(model.parameters(), lr=learning_rate)\n",
    "    else : raise ValueError('Unknown optimizer')\n",
    "    \n",
    "    criterion = nn.MSELoss() # As we are doing regression\n",
    "    \n",
    "    # Use chosen batch size instead of pre-defined one\n",
    "    train_loader = DataLoader(t_training, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(t_val, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Train the model, return validation loss\n",
    "    val_loss, trained_model = train_KAN(model, train_loader, val_loader, criterion, optimizer, epochs)\n",
    "    \n",
    "    return val_loss, trained_model\n",
    "\n",
    "\n",
    "\n",
    "def KAN_SAE_optimize(trial, SAE, input_size, optim : str = 'Adam') -> float:\n",
    "    # Hyper-parameters to be optimized\n",
    "    \n",
    "    hidden_layer_count = trial.suggest_int('hidden_layer_count', 2, 4) # inclusive\n",
    "    hidden_layer_sizes = [trial.suggest_categorical(f'hidden_layer_size_{i}', [640, 576, 512, 448, 256, 128, 64, 32, 16]) for i in range(hidden_layer_count)]\n",
    "    kan_layers = [input_size] + hidden_layer_sizes + [2] # Ensure correct input/output size\n",
    "    \n",
    "    print(kan_layers)\n",
    "    \n",
    "    lr = trial.suggest_float('lr', 0.001, 0.01)\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 512, step=16)\n",
    "    epochs = trial.suggest_int('epochs', 50, 150)\n",
    "    \n",
    "    # Initialize the model\n",
    "    model = KAN(kan_layers)\n",
    "    \n",
    "    if optim.lower() == 'adam': optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    elif optim.lower() == 'lbfgs': optimizer = torch.optim.LBFGS(model.parameters(), lr=lr)\n",
    "    else : raise ValueError('Unknown optimizer')\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Encode training and validation data using the stacked autoencoders in SAE\n",
    "    train_data_encoded = stacked_encode_data(X_train_tensor, SAE)\n",
    "    val_data_encoded = stacked_encode_data(X_val_tensor, SAE)\n",
    "    \n",
    "    train_loader = DataLoader(TensorDataset(train_data_encoded, y_train_tensor), batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(val_data_encoded, y_val_tensor), batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    \n",
    "    # Train the model, return validation loss\n",
    "    val_loss, trained_model = train_KAN(model, train_loader, val_loader, criterion, optimizer, epochs)\n",
    "    \n",
    "    return val_loss, trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following booleans to enable or disable the grid-search for the different models.\n",
    "# After running the grid-search, train the final models with the best hyperparameters.\n",
    "\n",
    "SEARCH_KAN_FULL = True \n",
    "SEARCH_KAN_REDUCED_128 = True\n",
    "SEARCH_KAN_REDUCED_64 = True \n",
    "\n",
    "TRIALS_KAN = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-14 22:05:44,916] A new study created in memory with name: no-name-26ef76ad-3494-4962-a235-a8c6e50bbe94\n",
      "[I 2024-06-14 22:06:39,023] Trial 0 finished with value: 1.0158858256680625 and parameters: {'hidden_layer_count': 2, 'hidden_layer_size_0': 256, 'hidden_layer_size_1': 640, 'lr': 0.007367183385594403, 'batch_size': 32, 'epochs': 82}. Best is trial 0 with value: 1.0158858256680625.\n",
      "[I 2024-06-14 22:06:49,777] Trial 1 finished with value: 0.9750261306762695 and parameters: {'hidden_layer_count': 4, 'hidden_layer_size_0': 16, 'hidden_layer_size_1': 640, 'hidden_layer_size_2': 32, 'hidden_layer_size_3': 32, 'lr': 0.007738691571910258, 'batch_size': 160, 'epochs': 136}. Best is trial 1 with value: 0.9750261306762695.\n",
      "[I 2024-06-14 22:07:04,995] Trial 2 finished with value: 0.8858040571212769 and parameters: {'hidden_layer_count': 3, 'hidden_layer_size_0': 64, 'hidden_layer_size_1': 448, 'hidden_layer_size_2': 64, 'lr': 0.0038690945142798865, 'batch_size': 112, 'epochs': 83}. Best is trial 2 with value: 0.8858040571212769.\n",
      "[I 2024-06-14 22:07:15,304] Trial 3 finished with value: 1.7039151787757874 and parameters: {'hidden_layer_count': 4, 'hidden_layer_size_0': 32, 'hidden_layer_size_1': 512, 'hidden_layer_size_2': 64, 'hidden_layer_size_3': 128, 'lr': 0.006516984649812006, 'batch_size': 384, 'epochs': 133}. Best is trial 2 with value: 0.8858040571212769.\n",
      "[I 2024-06-14 22:08:18,088] Trial 4 finished with value: 0.601089229186376 and parameters: {'hidden_layer_count': 4, 'hidden_layer_size_0': 448, 'hidden_layer_size_1': 640, 'hidden_layer_size_2': 16, 'hidden_layer_size_3': 32, 'lr': 0.0011380516791106557, 'batch_size': 192, 'epochs': 117}. Best is trial 4 with value: 0.601089229186376.\n",
      "[I 2024-06-14 22:08:42,911] Trial 5 finished with value: 0.9323394695917765 and parameters: {'hidden_layer_count': 3, 'hidden_layer_size_0': 512, 'hidden_layer_size_1': 32, 'hidden_layer_size_2': 16, 'lr': 0.008959504126775805, 'batch_size': 208, 'epochs': 54}. Best is trial 4 with value: 0.601089229186376.\n",
      "[I 2024-06-14 22:10:51,836] Trial 6 finished with value: 0.8027932643890381 and parameters: {'hidden_layer_count': 3, 'hidden_layer_size_0': 576, 'hidden_layer_size_1': 640, 'hidden_layer_size_2': 576, 'lr': 0.004713466684943697, 'batch_size': 160, 'epochs': 82}. Best is trial 4 with value: 0.601089229186376.\n",
      "[I 2024-06-14 22:12:08,318] Trial 7 finished with value: 0.7405673861503601 and parameters: {'hidden_layer_count': 4, 'hidden_layer_size_0': 128, 'hidden_layer_size_1': 448, 'hidden_layer_size_2': 640, 'hidden_layer_size_3': 512, 'lr': 0.0011959719604962512, 'batch_size': 176, 'epochs': 143}. Best is trial 4 with value: 0.601089229186376.\n",
      "[I 2024-06-14 22:12:52,737] Trial 8 finished with value: 0.7641021079487271 and parameters: {'hidden_layer_count': 3, 'hidden_layer_size_0': 16, 'hidden_layer_size_1': 448, 'hidden_layer_size_2': 448, 'lr': 0.0017176635965884435, 'batch_size': 48, 'epochs': 137}. Best is trial 4 with value: 0.601089229186376.\n",
      "[I 2024-06-14 22:13:56,861] Trial 9 finished with value: 0.8694070428609848 and parameters: {'hidden_layer_count': 2, 'hidden_layer_size_0': 576, 'hidden_layer_size_1': 256, 'lr': 0.004884534132548376, 'batch_size': 112, 'epochs': 120}. Best is trial 4 with value: 0.601089229186376.\n",
      "[I 2024-06-14 22:14:54,663] Trial 10 finished with value: 1.0812719464302063 and parameters: {'hidden_layer_count': 4, 'hidden_layer_size_0': 448, 'hidden_layer_size_1': 576, 'hidden_layer_size_2': 256, 'hidden_layer_size_3': 32, 'lr': 0.0029759704387133743, 'batch_size': 336, 'epochs': 108}. Best is trial 4 with value: 0.601089229186376.\n",
      "[I 2024-06-14 22:15:28,996] Trial 11 finished with value: 1.0118945240974426 and parameters: {'hidden_layer_count': 4, 'hidden_layer_size_0': 128, 'hidden_layer_size_1': 16, 'hidden_layer_size_2': 640, 'hidden_layer_size_3': 512, 'lr': 0.0010440127963523825, 'batch_size': 272, 'epochs': 146}. Best is trial 4 with value: 0.601089229186376.\n",
      "[I 2024-06-14 22:16:59,260] Trial 12 finished with value: 1.0111920833587646 and parameters: {'hidden_layer_count': 4, 'hidden_layer_size_0': 448, 'hidden_layer_size_1': 64, 'hidden_layer_size_2': 640, 'hidden_layer_size_3': 512, 'lr': 0.002870881285186282, 'batch_size': 496, 'epochs': 116}. Best is trial 4 with value: 0.601089229186376.\n",
      "[I 2024-06-14 22:17:19,726] Trial 13 finished with value: 0.8560594916343689 and parameters: {'hidden_layer_count': 4, 'hidden_layer_size_0': 128, 'hidden_layer_size_1': 128, 'hidden_layer_size_2': 16, 'hidden_layer_size_3': 16, 'lr': 0.002235497655115157, 'batch_size': 272, 'epochs': 99}. Best is trial 4 with value: 0.601089229186376.\n",
      "[I 2024-06-14 22:19:08,327] Trial 14 finished with value: 0.7062825262546539 and parameters: {'hidden_layer_count': 4, 'hidden_layer_size_0': 640, 'hidden_layer_size_1': 448, 'hidden_layer_size_2': 128, 'hidden_layer_size_3': 640, 'lr': 0.0010232335157948674, 'batch_size': 224, 'epochs': 149}. Best is trial 4 with value: 0.601089229186376.\n",
      "[I 2024-06-14 22:19:29,498] Trial 15 finished with value: 2.0136443972587585 and parameters: {'hidden_layer_count': 3, 'hidden_layer_size_0': 640, 'hidden_layer_size_1': 32, 'hidden_layer_size_2': 128, 'lr': 0.0034969590956835106, 'batch_size': 352, 'epochs': 121}. Best is trial 4 with value: 0.601089229186376.\n",
      "[I 2024-06-14 22:20:00,394] Trial 16 finished with value: 1.8295804858207703 and parameters: {'hidden_layer_count': 4, 'hidden_layer_size_0': 640, 'hidden_layer_size_1': 16, 'hidden_layer_size_2': 128, 'hidden_layer_size_3': 640, 'lr': 0.0098492265552022, 'batch_size': 240, 'epochs': 98}. Best is trial 4 with value: 0.601089229186376.\n",
      "[I 2024-06-14 22:21:14,120] Trial 17 finished with value: 1.1982592344284058 and parameters: {'hidden_layer_count': 2, 'hidden_layer_size_0': 448, 'hidden_layer_size_1': 512, 'lr': 0.0022188480240039696, 'batch_size': 432, 'epochs': 150}. Best is trial 4 with value: 0.601089229186376.\n",
      "[I 2024-06-14 22:22:48,291] Trial 18 finished with value: 1.4541165828704834 and parameters: {'hidden_layer_count': 4, 'hidden_layer_size_0': 640, 'hidden_layer_size_1': 576, 'hidden_layer_size_2': 512, 'hidden_layer_size_3': 640, 'lr': 0.006024696372573656, 'batch_size': 288, 'epochs': 128}. Best is trial 4 with value: 0.601089229186376.\n",
      "[I 2024-06-14 22:22:58,457] Trial 19 finished with value: 0.8974560275673866 and parameters: {'hidden_layer_count': 3, 'hidden_layer_size_0': 32, 'hidden_layer_size_1': 128, 'hidden_layer_size_2': 128, 'lr': 0.0045832248918066185, 'batch_size': 128, 'epochs': 107}. Best is trial 4 with value: 0.601089229186376.\n",
      "[I 2024-06-14 22:24:16,782] A new study created in memory with name: no-name-42cd2df1-3672-46c1-8c34-560fb28572fd\n",
      "[I 2024-06-14 22:24:31,715] Trial 0 finished with value: 1.6382017135620117 and parameters: {'hidden_layer_count': 2, 'hidden_layer_size_0': 448, 'hidden_layer_size_1': 64, 'lr': 0.004867184647664498, 'batch_size': 432, 'epochs': 142}. Best is trial 0 with value: 1.6382017135620117.\n",
      "[I 2024-06-14 22:24:38,671] Trial 1 finished with value: 1.2607893645763397 and parameters: {'hidden_layer_count': 4, 'hidden_layer_size_0': 64, 'hidden_layer_size_1': 64, 'hidden_layer_size_2': 32, 'hidden_layer_size_3': 256, 'lr': 0.001650129952864736, 'batch_size': 416, 'epochs': 129}. Best is trial 1 with value: 1.2607893645763397.\n",
      "[I 2024-06-14 22:24:41,962] Trial 2 finished with value: 2.362739324569702 and parameters: {'hidden_layer_count': 3, 'hidden_layer_size_0': 16, 'hidden_layer_size_1': 32, 'hidden_layer_size_2': 16, 'lr': 0.0012190515072265618, 'batch_size': 416, 'epochs': 55}. Best is trial 1 with value: 1.2607893645763397.\n",
      "[I 2024-06-14 22:24:57,415] Trial 3 finished with value: 1.2026665955781937 and parameters: {'hidden_layer_count': 3, 'hidden_layer_size_0': 640, 'hidden_layer_size_1': 32, 'hidden_layer_size_2': 16, 'lr': 0.0024085114959966265, 'batch_size': 128, 'epochs': 70}. Best is trial 3 with value: 1.2026665955781937.\n",
      "[I 2024-06-14 22:25:19,185] Trial 4 finished with value: 1.6321220397949219 and parameters: {'hidden_layer_count': 4, 'hidden_layer_size_0': 128, 'hidden_layer_size_1': 32, 'hidden_layer_size_2': 448, 'hidden_layer_size_3': 448, 'lr': 0.0077445864701130625, 'batch_size': 240, 'epochs': 112}. Best is trial 3 with value: 1.2026665955781937.\n",
      "[I 2024-06-14 22:25:33,612] Trial 5 finished with value: 1.88960462808609 and parameters: {'hidden_layer_count': 4, 'hidden_layer_size_0': 32, 'hidden_layer_size_1': 256, 'hidden_layer_size_2': 448, 'hidden_layer_size_3': 448, 'lr': 0.001304352982488249, 'batch_size': 272, 'epochs': 111}. Best is trial 3 with value: 1.2026665955781937.\n",
      "[I 2024-06-14 22:25:42,576] Trial 6 finished with value: 1.9930551946163177 and parameters: {'hidden_layer_count': 4, 'hidden_layer_size_0': 32, 'hidden_layer_size_1': 512, 'hidden_layer_size_2': 64, 'hidden_layer_size_3': 32, 'lr': 0.009840374528117323, 'batch_size': 112, 'epochs': 143}. Best is trial 3 with value: 1.2026665955781937.\n",
      "[I 2024-06-14 22:25:54,213] Trial 7 finished with value: 1.6129971345265706 and parameters: {'hidden_layer_count': 2, 'hidden_layer_size_0': 32, 'hidden_layer_size_1': 576, 'lr': 0.009103405968671888, 'batch_size': 144, 'epochs': 120}. Best is trial 3 with value: 1.2026665955781937.\n",
      "[I 2024-06-14 22:27:05,571] Trial 8 finished with value: 1.499093770980835 and parameters: {'hidden_layer_count': 4, 'hidden_layer_size_0': 640, 'hidden_layer_size_1': 640, 'hidden_layer_size_2': 448, 'hidden_layer_size_3': 256, 'lr': 0.004611530910982717, 'batch_size': 176, 'epochs': 55}. Best is trial 3 with value: 1.2026665955781937.\n",
      "[I 2024-06-14 22:27:19,248] Trial 9 finished with value: 1.2873432636260986 and parameters: {'hidden_layer_count': 2, 'hidden_layer_size_0': 128, 'hidden_layer_size_1': 256, 'lr': 0.00826723537725433, 'batch_size': 192, 'epochs': 81}. Best is trial 3 with value: 1.2026665955781937.\n",
      "[I 2024-06-14 22:27:55,536] Trial 10 finished with value: 1.4224606369222914 and parameters: {'hidden_layer_count': 3, 'hidden_layer_size_0': 640, 'hidden_layer_size_1': 128, 'hidden_layer_size_2': 576, 'lr': 0.0032696766474800284, 'batch_size': 32, 'epochs': 83}. Best is trial 3 with value: 1.2026665955781937.\n",
      "[I 2024-06-14 22:28:02,170] Trial 11 finished with value: 1.7713934183120728 and parameters: {'hidden_layer_count': 3, 'hidden_layer_size_0': 64, 'hidden_layer_size_1': 64, 'hidden_layer_size_2': 32, 'lr': 0.0028616616460379047, 'batch_size': 512, 'epochs': 84}. Best is trial 3 with value: 1.2026665955781937.\n",
      "[I 2024-06-14 22:28:12,501] Trial 12 finished with value: 1.3770604729652405 and parameters: {'hidden_layer_count': 3, 'hidden_layer_size_0': 64, 'hidden_layer_size_1': 448, 'hidden_layer_size_2': 32, 'lr': 0.002298942327075547, 'batch_size': 336, 'epochs': 128}. Best is trial 3 with value: 1.2026665955781937.\n",
      "[I 2024-06-14 22:28:36,831] Trial 13 finished with value: 1.3470049500465393 and parameters: {'hidden_layer_count': 3, 'hidden_layer_size_0': 512, 'hidden_layer_size_1': 16, 'hidden_layer_size_2': 256, 'lr': 0.006696307406395631, 'batch_size': 32, 'epochs': 68}. Best is trial 3 with value: 1.2026665955781937.\n",
      "[I 2024-06-14 22:28:47,738] Trial 14 finished with value: 2.021588087081909 and parameters: {'hidden_layer_count': 4, 'hidden_layer_size_0': 256, 'hidden_layer_size_1': 64, 'hidden_layer_size_2': 128, 'hidden_layer_size_3': 576, 'lr': 0.0037144647585760247, 'batch_size': 352, 'epochs': 98}. Best is trial 3 with value: 1.2026665955781937.\n",
      "[I 2024-06-14 22:29:06,125] Trial 15 finished with value: 1.2487322211265564 and parameters: {'hidden_layer_count': 3, 'hidden_layer_size_0': 576, 'hidden_layer_size_1': 32, 'hidden_layer_size_2': 16, 'lr': 0.001984349623681978, 'batch_size': 96, 'epochs': 94}. Best is trial 3 with value: 1.2026665955781937.\n",
      "[I 2024-06-14 22:29:23,514] Trial 16 finished with value: 1.1450007557868958 and parameters: {'hidden_layer_count': 3, 'hidden_layer_size_0': 576, 'hidden_layer_size_1': 32, 'hidden_layer_size_2': 16, 'lr': 0.005810317367343633, 'batch_size': 80, 'epochs': 95}. Best is trial 16 with value: 1.1450007557868958.\n",
      "[I 2024-06-14 22:29:45,173] Trial 17 finished with value: 1.2356515924135845 and parameters: {'hidden_layer_count': 2, 'hidden_layer_size_0': 576, 'hidden_layer_size_1': 32, 'lr': 0.006205419719622769, 'batch_size': 80, 'epochs': 67}. Best is trial 16 with value: 1.1450007557868958.\n",
      "[I 2024-06-14 22:30:03,035] Trial 18 finished with value: 1.52598375082016 and parameters: {'hidden_layer_count': 3, 'hidden_layer_size_0': 640, 'hidden_layer_size_1': 32, 'hidden_layer_size_2': 16, 'lr': 0.005790769157819823, 'batch_size': 240, 'epochs': 70}. Best is trial 16 with value: 1.1450007557868958.\n",
      "[I 2024-06-14 22:31:07,634] Trial 19 finished with value: 1.1540069920676095 and parameters: {'hidden_layer_count': 2, 'hidden_layer_size_0': 576, 'hidden_layer_size_1': 640, 'lr': 0.004196555070762968, 'batch_size': 32, 'epochs': 93}. Best is trial 16 with value: 1.1450007557868958.\n",
      "[I 2024-06-14 22:31:34,256] A new study created in memory with name: no-name-230aa5a6-2d10-487a-aeab-d66257636787\n",
      "[I 2024-06-14 22:31:48,286] Trial 0 finished with value: 1.5955045819282532 and parameters: {'hidden_layer_count': 2, 'hidden_layer_size_0': 640, 'hidden_layer_size_1': 256, 'lr': 0.003923532167045609, 'batch_size': 336, 'epochs': 94}. Best is trial 0 with value: 1.5955045819282532.\n",
      "[I 2024-06-14 22:32:04,732] Trial 1 finished with value: 1.3043206201659308 and parameters: {'hidden_layer_count': 2, 'hidden_layer_size_0': 64, 'hidden_layer_size_1': 448, 'lr': 0.008736267972309593, 'batch_size': 48, 'epochs': 65}. Best is trial 1 with value: 1.3043206201659308.\n",
      "[I 2024-06-14 22:32:08,530] Trial 2 finished with value: 1.6738457679748535 and parameters: {'hidden_layer_count': 2, 'hidden_layer_size_0': 32, 'hidden_layer_size_1': 64, 'lr': 0.008418991383638151, 'batch_size': 224, 'epochs': 94}. Best is trial 1 with value: 1.3043206201659308.\n",
      "[I 2024-06-14 22:32:27,599] Trial 3 finished with value: 1.3820533057053883 and parameters: {'hidden_layer_count': 2, 'hidden_layer_size_0': 128, 'hidden_layer_size_1': 512, 'lr': 0.009903373138661395, 'batch_size': 80, 'epochs': 129}. Best is trial 1 with value: 1.3043206201659308.\n",
      "[I 2024-06-14 22:32:57,037] Trial 4 finished with value: 1.6965653278209545 and parameters: {'hidden_layer_count': 2, 'hidden_layer_size_0': 512, 'hidden_layer_size_1': 512, 'lr': 0.003970800664968601, 'batch_size': 16, 'epochs': 74}. Best is trial 1 with value: 1.3043206201659308.\n",
      "[I 2024-06-14 22:33:14,801] Trial 5 finished with value: 1.4816431403160095 and parameters: {'hidden_layer_count': 4, 'hidden_layer_size_0': 576, 'hidden_layer_size_1': 32, 'hidden_layer_size_2': 448, 'hidden_layer_size_3': 512, 'lr': 0.003513723127312874, 'batch_size': 400, 'epochs': 102}. Best is trial 1 with value: 1.3043206201659308.\n",
      "[I 2024-06-14 22:33:33,214] Trial 6 finished with value: 1.4266397356987 and parameters: {'hidden_layer_count': 2, 'hidden_layer_size_0': 512, 'hidden_layer_size_1': 128, 'lr': 0.005284494673881793, 'batch_size': 256, 'epochs': 146}. Best is trial 1 with value: 1.3043206201659308.\n",
      "[I 2024-06-14 22:33:41,513] Trial 7 finished with value: 1.4458577036857605 and parameters: {'hidden_layer_count': 2, 'hidden_layer_size_0': 448, 'hidden_layer_size_1': 32, 'lr': 0.0018772252110595535, 'batch_size': 112, 'epochs': 112}. Best is trial 1 with value: 1.3043206201659308.\n",
      "[I 2024-06-14 22:34:49,902] Trial 8 finished with value: 1.5064547260602315 and parameters: {'hidden_layer_count': 4, 'hidden_layer_size_0': 448, 'hidden_layer_size_1': 64, 'hidden_layer_size_2': 64, 'hidden_layer_size_3': 512, 'lr': 0.00837113895074523, 'batch_size': 16, 'epochs': 88}. Best is trial 1 with value: 1.3043206201659308.\n",
      "[I 2024-06-14 22:35:02,568] Trial 9 finished with value: 1.1178654730319977 and parameters: {'hidden_layer_count': 4, 'hidden_layer_size_0': 256, 'hidden_layer_size_1': 32, 'hidden_layer_size_2': 64, 'hidden_layer_size_3': 64, 'lr': 0.003020886607846605, 'batch_size': 240, 'epochs': 149}. Best is trial 9 with value: 1.1178654730319977.\n",
      "[I 2024-06-14 22:35:14,505] Trial 10 finished with value: 1.5397989749908447 and parameters: {'hidden_layer_count': 3, 'hidden_layer_size_0': 256, 'hidden_layer_size_1': 16, 'hidden_layer_size_2': 16, 'lr': 0.0011800716886861849, 'batch_size': 496, 'epochs': 148}. Best is trial 9 with value: 1.1178654730319977.\n",
      "[I 2024-06-14 22:35:46,613] Trial 11 finished with value: 1.3144535621007283 and parameters: {'hidden_layer_count': 3, 'hidden_layer_size_0': 64, 'hidden_layer_size_1': 448, 'hidden_layer_size_2': 640, 'lr': 0.006334186558864398, 'batch_size': 160, 'epochs': 53}. Best is trial 9 with value: 1.1178654730319977.\n",
      "[I 2024-06-14 22:35:58,133] Trial 12 finished with value: 1.490967591603597 and parameters: {'hidden_layer_count': 4, 'hidden_layer_size_0': 64, 'hidden_layer_size_1': 448, 'hidden_layer_size_2': 64, 'hidden_layer_size_3': 64, 'lr': 0.006866352419564362, 'batch_size': 160, 'epochs': 51}. Best is trial 9 with value: 1.1178654730319977.\n",
      "[I 2024-06-14 22:36:19,901] Trial 13 finished with value: 1.2208261489868164 and parameters: {'hidden_layer_count': 3, 'hidden_layer_size_0': 256, 'hidden_layer_size_1': 640, 'hidden_layer_size_2': 256, 'lr': 0.002285431265110922, 'batch_size': 336, 'epochs': 72}. Best is trial 9 with value: 1.1178654730319977.\n",
      "[I 2024-06-14 22:36:39,181] Trial 14 finished with value: 1.5708260536193848 and parameters: {'hidden_layer_count': 3, 'hidden_layer_size_0': 256, 'hidden_layer_size_1': 640, 'hidden_layer_size_2': 256, 'lr': 0.0028177773441829786, 'batch_size': 352, 'epochs': 120}. Best is trial 9 with value: 1.1178654730319977.\n",
      "[I 2024-06-14 22:37:35,066] Trial 15 finished with value: 1.1366767585277557 and parameters: {'hidden_layer_count': 4, 'hidden_layer_size_0': 256, 'hidden_layer_size_1': 640, 'hidden_layer_size_2': 512, 'hidden_layer_size_3': 256, 'lr': 0.0024130943690011883, 'batch_size': 320, 'epochs': 76}. Best is trial 9 with value: 1.1178654730319977.\n",
      "[I 2024-06-14 22:38:06,434] Trial 16 finished with value: 1.730860948562622 and parameters: {'hidden_layer_count': 4, 'hidden_layer_size_0': 16, 'hidden_layer_size_1': 576, 'hidden_layer_size_2': 512, 'hidden_layer_size_3': 256, 'lr': 0.0048236437029507175, 'batch_size': 448, 'epochs': 79}. Best is trial 9 with value: 1.1178654730319977.\n",
      "[I 2024-06-14 22:38:19,327] Trial 17 finished with value: 1.2838683128356934 and parameters: {'hidden_layer_count': 4, 'hidden_layer_size_0': 256, 'hidden_layer_size_1': 32, 'hidden_layer_size_2': 512, 'hidden_layer_size_3': 64, 'lr': 0.0010267821796354183, 'batch_size': 288, 'epochs': 128}. Best is trial 9 with value: 1.1178654730319977.\n",
      "[I 2024-06-14 22:38:54,374] Trial 18 finished with value: 0.8947936991850535 and parameters: {'hidden_layer_count': 4, 'hidden_layer_size_0': 256, 'hidden_layer_size_1': 640, 'hidden_layer_size_2': 128, 'hidden_layer_size_3': 256, 'lr': 0.0031196522061209407, 'batch_size': 208, 'epochs': 137}. Best is trial 18 with value: 0.8947936991850535.\n",
      "[I 2024-06-14 22:39:09,281] Trial 19 finished with value: 0.8822043637434641 and parameters: {'hidden_layer_count': 3, 'hidden_layer_size_0': 128, 'hidden_layer_size_1': 256, 'hidden_layer_size_2': 128, 'lr': 0.004407990786721218, 'batch_size': 208, 'epochs': 139}. Best is trial 19 with value: 0.8822043637434641.\n"
     ]
    }
   ],
   "source": [
    "%%capture KAN_opt_out\n",
    "\n",
    "import optuna\n",
    "\n",
    "def save_best_KAN(study, input_size, path, SAE=None):\n",
    "    best_trial = study.best_trial\n",
    "    \n",
    "    kan_layers = [input_size] + [best_trial.params[f'hidden_layer_size_{i}'] for i in range(best_trial.params['hidden_layer_count'])] + [2]\n",
    "    \n",
    "    model = KAN(kan_layers)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=best_trial.params['lr'])\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    if SAE is not None: # Encode training and validation data using the stacked autoencoders in SAE\n",
    "        train_data_encoded = stacked_encode_data(X_train_tensor, SAE)\n",
    "        val_data_encoded = stacked_encode_data(X_val_tensor, SAE)\n",
    "        \n",
    "        train_loader = DataLoader(TensorDataset(train_data_encoded, y_train_tensor), batch_size=best_trial.params['batch_size'], shuffle=True)\n",
    "        val_loader = DataLoader(TensorDataset(val_data_encoded, y_val_tensor), batch_size=best_trial.params['batch_size'], shuffle=True)\n",
    "    else :\n",
    "        train_loader = DataLoader(t_training, batch_size=best_trial.params['batch_size'], shuffle=True)\n",
    "        val_loader = DataLoader(t_val, batch_size=best_trial.params['batch_size'], shuffle=True)\n",
    "    \n",
    "    val_loss, trained_model = train_KAN(model, train_loader, val_loader, criterion, optimizer, best_trial.params['epochs'])\n",
    "    \n",
    "    torch.save(trained_model.state_dict(), path)\n",
    "\n",
    "\n",
    "\n",
    "if SEARCH_KAN_FULL:\n",
    "    print('Starting KAN full grid search')\n",
    "\n",
    "    # Optuna study object and direction (minimize validation loss)\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    # study.optimize(MLP_full_gridsearch, n_trials=2)\n",
    "    study.optimize(lambda trial: KAN_full_optimize(trial, 'Adam')[0], n_trials=TRIALS_KAN)\n",
    "\n",
    "    pretty_print_study(study)\n",
    "    save_best_KAN(study, 448, f'./models/KAN/full_KAN.pth')\n",
    "\n",
    "else: print('Skipping SEARCH_KAN_FULL')\n",
    "\n",
    "print('\\n====================================')\n",
    "print('V results for SEARCH_KAN_REDUCED_128 V')\n",
    "print('====================================\\n')\n",
    "\n",
    "if SEARCH_KAN_REDUCED_128:\n",
    "    print('Starting KAN reduced search for 256-128 SAE')\n",
    "\n",
    "    encoders = train_stacked_autoencoders(X_train_tensor, 448, [256, 128], 20)\n",
    "    \n",
    "    # Save the encoders for later use\n",
    "    for i, enc in enumerate(encoders):\n",
    "        torch.save(enc.state_dict(), f'./models/KAN/128_encoder_{int(256 * 0.5**i)}.pth')\n",
    "    \n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(lambda trial: KAN_SAE_optimize(trial, encoders, 128, 'Adam')[0], n_trials=TRIALS_KAN)\n",
    "    \n",
    "    pretty_print_study(study)\n",
    "    save_best_KAN(study, 128, f'./models/KAN/128_KAN.pth', encoders)\n",
    "\n",
    "else: print('Skipping SEARCH_KAN_REDUCED_128') \n",
    "\n",
    "print('\\n====================================')\n",
    "print('V results for SEARCH_KAN_REDUCED_64 V')\n",
    "print('====================================\\n')\n",
    "\n",
    "if SEARCH_KAN_REDUCED_64:\n",
    "    print('Starting KAN reduced grid search for 256-128-64 SAE')\n",
    "\n",
    "    encoders = train_stacked_autoencoders(X_train_tensor, 448, [256, 128, 64], 20)\n",
    "    \n",
    "    # Save the encoders for later use\n",
    "    for i, enc in enumerate(encoders):\n",
    "        torch.save(enc.state_dict(), f'./models/KAN/64_encoder_{int(256 * 0.5**i)}.pth')\n",
    "    \n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(lambda trial: KAN_SAE_optimize(trial, encoders, 64, 'Adam')[0], n_trials=TRIALS_KAN)\n",
    "    \n",
    "    pretty_print_study(study)\n",
    "    save_best_KAN(study, 64, f'./models/KAN/64_KAN.pth', encoders)\n",
    "\n",
    "else: print('Skipping SEARCH_KAN_REDUCED_64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "filename = now.strftime(\"./optimization/KAN/KAN optimization 448AP - \"\"%Y-%m-%d-%H-%M-%S\") + '.txt'\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "    f.write(KAN_opt_out.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation is disabled\n"
     ]
    }
   ],
   "source": [
    "perform_evaluation = False\n",
    "\n",
    "\n",
    "model_paths = {\n",
    "    'MLP': {\n",
    "        'full': './models/MLP/full_MLP.pth',\n",
    "        '256': './models/MLP/256_MLP.pth',\n",
    "        '64': './models/MLP/64_MLP.pth'\n",
    "    },\n",
    "    'KAN': {\n",
    "        'full': './models/KAN/full_KAN.pth',\n",
    "        '256': './models/KAN/256_KAN.pth',\n",
    "        '64': './models/KAN/64_KAN.pth'\n",
    "    }\n",
    "}\n",
    "\n",
    "SAE_paths = {\n",
    "    'MLP': {\n",
    "        '256': ['./models/MLP/256_encoder_512.pth', './models/MLP/256_encoder_256.pth'],\n",
    "        '64': ['./models/MLP/128_encoder_512.pth', './models/MLP/128_encoder_256.pth', './models/MLP/128_encoder_128.pth']\n",
    "    },\n",
    "    'KAN': {\n",
    "        '256': ['./models/KAN/256_encoder_512.pth', './models/KAN/256_encoder_256.pth'],\n",
    "        '64': ['./models/KAN/128_encoder_512.pth', './models/KAN/128_encoder_256.pth', './models/KAN/128_encoder_128.pth']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Load the saved MLP models\n",
    "def load_MLP_model(path, hidden_layer_sizes, dropout_rate, input_size):\n",
    "    model = MLP(hidden_layer_sizes, dropout_rate, input_size)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    return model\n",
    "\n",
    "# Load the saved KAN models\n",
    "def load_KAN_model(path, hidden_layer_sizes, input_size):\n",
    "    kan_layers = [input_size] + hidden_layer_sizes + [2]\n",
    "    model = KAN(kan_layers)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    return model\n",
    "\n",
    "# Example, if final_size is 64, the SAE will have 256 -> 128 -> 64\n",
    "# So we need to instantiate and load three autoencoders in the correct order\n",
    "# and then load them from the path\n",
    "def load_SAE(paths, final_size):\n",
    "    encoders = []\n",
    "    input_dim = 448\n",
    "    for i, path in enumerate(paths):\n",
    "        current_dim = 256 * 0.5**i\n",
    "        current_dim = int(current_dim)\n",
    "        if current_dim < final_size: # Should not happen, but just in case\n",
    "            break\n",
    "        encoder = Autoencoder(input_dim, current_dim)\n",
    "        encoder.load_state_dict(torch.load(path))\n",
    "        encoder.eval() # Set model to evaluation mode\n",
    "        encoders.append(encoder)\n",
    "\n",
    "        input_dim = current_dim\n",
    "    \n",
    "    return encoders\n",
    "\n",
    "if not perform_evaluation:\n",
    "    print('Evaluation is disabled')\n",
    "    \n",
    "else:\n",
    "    # TODO: Find a way to get the hyperparameters from before ==> LAYERS AND DROPOUT RATE MUST BE ADDED BY HAND FOR NOW\n",
    "    \n",
    "    # Load the MLP models\n",
    "    mlp_full = load_MLP_model(model_paths['MLP']['full'], [256, 256, 256, 620], 0.500715044695168, 448)\n",
    "    mlp_128 = load_MLP_model(model_paths['MLP']['128'], [256, 256], 0.29939913412687036, 128)\n",
    "    mlp_64 = load_MLP_model(model_paths['MLP']['64'], [620, 620, 512], 0.4381069933899059, 64)\n",
    "\n",
    "    # Load the KAN models\n",
    "    kan_full = load_KAN_model(model_paths['KAN']['full'], [256, 128, 256, 32], 448)\n",
    "    kan_128 = load_KAN_model(model_paths['KAN']['128'], [32, 64, 256, 64], 128)\n",
    "    kan_64 = load_KAN_model(model_paths['KAN']['64'], [700, 620, 32], 64)\n",
    "    \n",
    "    # Load the SAE models\n",
    "    mlp_SAE_128 = load_SAE(SAE_paths['MLP']['128'], 128)\n",
    "    mlp_SAE_64 = load_SAE(SAE_paths['MLP']['64'], 64)\n",
    "    kan_SAE_128 = load_SAE(SAE_paths['KAN']['128'], 128)\n",
    "    kan_SAE_64 = load_SAE(SAE_paths['KAN']['64'], 64)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation is disabled\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, test_features, test_labels):\n",
    "    with torch.no_grad():\n",
    "        predictions = model(test_features).cpu().numpy() # Predictions from the model (on CPU) - we need to move them to CPU to use numpy\n",
    "        euc_distances = np.sqrt(np.sum((predictions - test_labels.cpu().numpy())**2, axis=1)) # Euclidean distance between predictions and ground-truth\n",
    "        \n",
    "    return euc_distances\n",
    "\n",
    "if not perform_evaluation:\n",
    "    print('Evaluation is disabled')\n",
    "else:\n",
    "    # Test tensors are defined previously as X_test_tensor and y_test_tensor\n",
    "    # and we have def stacked_encode_data(data, encoders): to encode the data\n",
    "    \n",
    "    # Encode the test data using the stacked autoencoders\n",
    "    mlp_test_data_encoded_128 = stacked_encode_data(X_test_tensor, mlp_SAE_128)\n",
    "    mlp_test_data_encoded_64 = stacked_encode_data(X_test_tensor, mlp_SAE_64)\n",
    "    kan_test_data_encoded_128 = stacked_encode_data(X_test_tensor, kan_SAE_128)\n",
    "    kan_test_data_encoded_64 = stacked_encode_data(X_test_tensor, kan_SAE_64)\n",
    "    \n",
    "    # Convert the encoded data to PyTorch Tensors\n",
    "    # mlp_test_data_encoded_256 = torch.tensor(mlp_test_data_encoded_256, dtype=torch.float32)\n",
    "    # mlp_test_data_encoded_128 = torch.tensor(mlp_test_data_encoded_128, dtype=torch.float32)\n",
    "    # kan_test_data_encoded_256 = torch.tensor(kan_test_data_encoded_256, dtype=torch.float32)\n",
    "    # kan_test_data_encoded_128 = torch.tensor(kan_test_data_encoded_128, dtype=torch.float32)\n",
    "    \n",
    "    # Evaluate the models\n",
    "    mlp_full_distances = evaluate_model(mlp_full, X_test_tensor, y_test_tensor)\n",
    "    mlp_128_distances = evaluate_model(mlp_128, mlp_test_data_encoded_128, y_test_tensor)\n",
    "    mlp_64_distances = evaluate_model(mlp_64, mlp_test_data_encoded_64, y_test_tensor)\n",
    "    \n",
    "    kan_full_distances = evaluate_model(kan_full, X_test_tensor, y_test_tensor)\n",
    "    kan_128_distances = evaluate_model(kan_128, kan_test_data_encoded_128, y_test_tensor)\n",
    "    kan_64_distances = evaluate_model(kan_64, kan_test_data_encoded_64, y_test_tensor)\n",
    "    \n",
    "    # Print the shapes\n",
    "    print(mlp_full_distances.shape)\n",
    "    print(mlp_128_distances.shape)\n",
    "    print(mlp_64_distances.shape)\n",
    "    \n",
    "    print(kan_full_distances.shape)\n",
    "    print(kan_128_distances.shape)\n",
    "    print(kan_64_distances.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation is disabled\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if not perform_evaluation:\n",
    "    print('Evaluation is disabled')\n",
    "else:\n",
    "    data = {\n",
    "        'MLP_64': mlp_64_distances,\n",
    "        'MLP_128': mlp_128_distances,\n",
    "        'MLP_full': mlp_full_distances,\n",
    "        'KAN_64': kan_64_distances,\n",
    "        'KAN_128': kan_128_distances,\n",
    "        'KAN_full': kan_full_distances\n",
    "    }\n",
    "    \n",
    "    # Create boxplots for the results\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    axes[0].boxplot([data['MLP_full'], data['KAN_full']], labels=['MLP_full', 'KAN_full'])\n",
    "    axes[0].set_title('Full models')\n",
    "    \n",
    "    axes[1].boxplot([data['MLP_128'], data['KAN_128']], labels=['MLP_128', 'KAN_128'])\n",
    "    axes[1].set_title('Reduced models (128)')\n",
    "    \n",
    "    axes[2].boxplot([data['MLP_64'], data['KAN_64']], labels=['MLP_64', 'KAN_64'])\n",
    "    axes[2].set_title('Reduced models (64)')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Print model statistics: 25th, 50th (median), 75th percentiles, and the amount or percentage of outliers\n",
    "    for key in data:\n",
    "        print(\"====================================\")\n",
    "        print(\"Statistics for \", key)\n",
    "        distances = data[key]\n",
    "        q25, q50, q75 = np.percentile(distances, [25, 50, 75])\n",
    "        iqr = q75 - q25\n",
    "        lower_bound = q25 - 1.5 * iqr\n",
    "        upper_bound = q75 + 1.5 * iqr\n",
    "        outliers = np.sum((distances < lower_bound) | (distances > upper_bound))\n",
    "        print(f'{key}: 25th percentile: {q25:.2f} - 50th percentile: {q50:.2f} - 75th percentile: {q75:.2f} - Outliers: {outliers} ({outliers/len(distances)*100:.2f}%)')\n",
    "        \n",
    "        # Print max predicted distance\n",
    "        max_distance = np.max(distances)\n",
    "        print(f'Max distance: {max_distance:.2f}')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
